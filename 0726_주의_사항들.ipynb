{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/youngjinjae/pythontest/blob/main/0726_%EC%A3%BC%EC%9D%98_%EC%82%AC%ED%95%AD%EB%93%A4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d141c47",
      "metadata": {
        "id": "7d141c47",
        "outputId": "0e9f0bea-9834-401b-867d-64a8762b90e4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LinearRegression()"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 학습 데이터와 평가데이터의 분리\n",
        "# training data, validation data, test data\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import linear_model\n",
        "\n",
        "raw_df = pd.read_csv('./data/ozone/ozone.csv')\n",
        "#1) 결치값 처리\n",
        "#2) 이강치 처리\n",
        "#3) 정규화 처리\n",
        "\n",
        "df = raw_df.dropna(how='any') # any 행 있으면 날려버려라\n",
        "# df = raw_df.dropna(how='any')\n",
        "# print(df.shape)\n",
        "# display(df)\n",
        "\n",
        "# 데이터셋을 분리\n",
        "x_data = df[['Solar.R','Wind','Temp']].values\n",
        "t_data = df['Ozone'].values.reshape(-1,1)\n",
        "\n",
        "# 이제 학습데이터와 test 데이터 분리\n",
        "(x_data_train, x_data_test, t_data_train, t_data_test) = \\\n",
        "train_test_split(x_data,\n",
        "                t_data,\n",
        "                test_size=0.3,\n",
        "                random_state=0)\n",
        "# 항상 같은 값 잡아라 seed값 잡기\n",
        "# 파이썬에 특징 \\ 밑에 이어준다. xdata 부터~ t_data test 까지\n",
        "model = linear_model.LinearRegression()\n",
        "\n",
        "# 학습을 진행\n",
        "model.fit(x_data_train, t_data_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d04038a",
      "metadata": {
        "scrolled": true,
        "id": "9d04038a",
        "outputId": "da842505-dc0b-4326-e59c-99a0cf62db1f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>height</th>\n",
              "      <th>weight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>188</td>\n",
              "      <td>71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>161</td>\n",
              "      <td>68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>178</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>136</td>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>145</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  height  weight\n",
              "0      1     188      71\n",
              "1      2     161      68\n",
              "2      0     178      52\n",
              "3      2     136      63\n",
              "4      1     145      52"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "(20000, 3)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label     0\n",
            "height    0\n",
            "weight    0\n",
            "dtype: int64\n",
            "Epoch 1/100\n",
            "112/112 [==============================] - 1s 3ms/step - loss: 0.9273 - accuracy: 0.5608 - val_loss: 0.8163 - val_accuracy: 0.6511\n",
            "Epoch 2/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.7554 - accuracy: 0.7062 - val_loss: 0.6953 - val_accuracy: 0.7650\n",
            "Epoch 3/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.6557 - accuracy: 0.7829 - val_loss: 0.6156 - val_accuracy: 0.8011\n",
            "Epoch 4/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.5877 - accuracy: 0.8184 - val_loss: 0.5590 - val_accuracy: 0.8382\n",
            "Epoch 5/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.5369 - accuracy: 0.8457 - val_loss: 0.5138 - val_accuracy: 0.8471\n",
            "Epoch 6/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.4968 - accuracy: 0.8670 - val_loss: 0.4790 - val_accuracy: 0.8768\n",
            "Epoch 7/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.4641 - accuracy: 0.8840 - val_loss: 0.4481 - val_accuracy: 0.8711\n",
            "Epoch 8/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.4362 - accuracy: 0.9004 - val_loss: 0.4226 - val_accuracy: 0.8932\n",
            "Epoch 9/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.4123 - accuracy: 0.9142 - val_loss: 0.4009 - val_accuracy: 0.9093\n",
            "Epoch 10/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.3916 - accuracy: 0.9264 - val_loss: 0.3824 - val_accuracy: 0.9279\n",
            "Epoch 11/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.3733 - accuracy: 0.9355 - val_loss: 0.3662 - val_accuracy: 0.9357\n",
            "Epoch 12/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.3573 - accuracy: 0.9433 - val_loss: 0.3492 - val_accuracy: 0.9407\n",
            "Epoch 13/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.3428 - accuracy: 0.9493 - val_loss: 0.3358 - val_accuracy: 0.9475\n",
            "Epoch 14/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.9560 - val_loss: 0.3241 - val_accuracy: 0.9504\n",
            "Epoch 15/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.3177 - accuracy: 0.9579 - val_loss: 0.3117 - val_accuracy: 0.9561\n",
            "Epoch 16/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.3063 - accuracy: 0.9574 - val_loss: 0.3021 - val_accuracy: 0.9543\n",
            "Epoch 17/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.2964 - accuracy: 0.9626 - val_loss: 0.2913 - val_accuracy: 0.9654\n",
            "Epoch 18/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.2868 - accuracy: 0.9668 - val_loss: 0.2824 - val_accuracy: 0.9632\n",
            "Epoch 19/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.2781 - accuracy: 0.9664 - val_loss: 0.2741 - val_accuracy: 0.9693\n",
            "Epoch 20/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.2698 - accuracy: 0.9657 - val_loss: 0.2664 - val_accuracy: 0.9696\n",
            "Epoch 21/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.2624 - accuracy: 0.9709 - val_loss: 0.2594 - val_accuracy: 0.9700\n",
            "Epoch 22/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.2554 - accuracy: 0.9704 - val_loss: 0.2526 - val_accuracy: 0.9700\n",
            "Epoch 23/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.2486 - accuracy: 0.9726 - val_loss: 0.2464 - val_accuracy: 0.9696\n",
            "Epoch 24/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.2422 - accuracy: 0.9733 - val_loss: 0.2401 - val_accuracy: 0.9736\n",
            "Epoch 25/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.2364 - accuracy: 0.9745 - val_loss: 0.2344 - val_accuracy: 0.9725\n",
            "Epoch 26/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.2307 - accuracy: 0.9754 - val_loss: 0.2292 - val_accuracy: 0.9743\n",
            "Epoch 27/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.2255 - accuracy: 0.9766 - val_loss: 0.2241 - val_accuracy: 0.9746\n",
            "Epoch 28/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.2204 - accuracy: 0.9767 - val_loss: 0.2196 - val_accuracy: 0.9732\n",
            "Epoch 29/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.2157 - accuracy: 0.9762 - val_loss: 0.2144 - val_accuracy: 0.9786\n",
            "Epoch 30/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.2113 - accuracy: 0.9765 - val_loss: 0.2101 - val_accuracy: 0.9775\n",
            "Epoch 31/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.2070 - accuracy: 0.9776 - val_loss: 0.2060 - val_accuracy: 0.9775\n",
            "Epoch 32/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.2028 - accuracy: 0.9787 - val_loss: 0.2022 - val_accuracy: 0.9793\n",
            "Epoch 33/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1989 - accuracy: 0.9777 - val_loss: 0.1982 - val_accuracy: 0.9789\n",
            "Epoch 34/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1952 - accuracy: 0.9783 - val_loss: 0.1946 - val_accuracy: 0.9804\n",
            "Epoch 35/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1916 - accuracy: 0.9769 - val_loss: 0.1911 - val_accuracy: 0.9793\n",
            "Epoch 36/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1880 - accuracy: 0.9784 - val_loss: 0.1878 - val_accuracy: 0.9800\n",
            "Epoch 37/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1849 - accuracy: 0.9779 - val_loss: 0.1846 - val_accuracy: 0.9786\n",
            "Epoch 38/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1817 - accuracy: 0.9785 - val_loss: 0.1818 - val_accuracy: 0.9771\n",
            "Epoch 39/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1786 - accuracy: 0.9784 - val_loss: 0.1787 - val_accuracy: 0.9814\n",
            "Epoch 40/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1758 - accuracy: 0.9804 - val_loss: 0.1761 - val_accuracy: 0.9779\n",
            "Epoch 41/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1730 - accuracy: 0.9787 - val_loss: 0.1733 - val_accuracy: 0.9804\n",
            "Epoch 42/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1703 - accuracy: 0.9797 - val_loss: 0.1706 - val_accuracy: 0.9814\n",
            "Epoch 43/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1678 - accuracy: 0.9786 - val_loss: 0.1681 - val_accuracy: 0.9818\n",
            "Epoch 44/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1652 - accuracy: 0.9804 - val_loss: 0.1665 - val_accuracy: 0.9764\n",
            "Epoch 45/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1630 - accuracy: 0.9793 - val_loss: 0.1636 - val_accuracy: 0.9779\n",
            "Epoch 46/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1609 - accuracy: 0.9799 - val_loss: 0.1614 - val_accuracy: 0.9807\n",
            "Epoch 47/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1586 - accuracy: 0.9789 - val_loss: 0.1594 - val_accuracy: 0.9814\n",
            "Epoch 48/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1564 - accuracy: 0.9796 - val_loss: 0.1573 - val_accuracy: 0.9829\n",
            "Epoch 49/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1543 - accuracy: 0.9813 - val_loss: 0.1551 - val_accuracy: 0.9814\n",
            "Epoch 50/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1524 - accuracy: 0.9799 - val_loss: 0.1532 - val_accuracy: 0.9800\n",
            "Epoch 51/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1504 - accuracy: 0.9807 - val_loss: 0.1514 - val_accuracy: 0.9832\n",
            "Epoch 52/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1487 - accuracy: 0.9804 - val_loss: 0.1496 - val_accuracy: 0.9821\n",
            "Epoch 53/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1468 - accuracy: 0.9812 - val_loss: 0.1481 - val_accuracy: 0.9796\n",
            "Epoch 54/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1453 - accuracy: 0.9804 - val_loss: 0.1466 - val_accuracy: 0.9793\n",
            "Epoch 55/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1436 - accuracy: 0.9811 - val_loss: 0.1446 - val_accuracy: 0.9821\n",
            "Epoch 56/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1421 - accuracy: 0.9796 - val_loss: 0.1432 - val_accuracy: 0.9814\n",
            "Epoch 57/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1404 - accuracy: 0.9802 - val_loss: 0.1423 - val_accuracy: 0.9779\n",
            "Epoch 58/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1389 - accuracy: 0.9801 - val_loss: 0.1401 - val_accuracy: 0.9825\n",
            "Epoch 59/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1373 - accuracy: 0.9805 - val_loss: 0.1389 - val_accuracy: 0.9832\n",
            "Epoch 60/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1363 - accuracy: 0.9809 - val_loss: 0.1374 - val_accuracy: 0.9818\n",
            "Epoch 61/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1347 - accuracy: 0.9803 - val_loss: 0.1362 - val_accuracy: 0.9839\n",
            "Epoch 62/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1335 - accuracy: 0.9812 - val_loss: 0.1346 - val_accuracy: 0.9814\n",
            "Epoch 63/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1321 - accuracy: 0.9809 - val_loss: 0.1333 - val_accuracy: 0.9818\n",
            "Epoch 64/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1307 - accuracy: 0.9811 - val_loss: 0.1322 - val_accuracy: 0.9825\n",
            "Epoch 65/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1296 - accuracy: 0.9796 - val_loss: 0.1310 - val_accuracy: 0.9818\n",
            "Epoch 66/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1286 - accuracy: 0.9818 - val_loss: 0.1298 - val_accuracy: 0.9821\n",
            "Epoch 67/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1274 - accuracy: 0.9812 - val_loss: 0.1288 - val_accuracy: 0.9825\n",
            "Epoch 68/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1263 - accuracy: 0.9820 - val_loss: 0.1285 - val_accuracy: 0.9814\n",
            "Epoch 69/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1252 - accuracy: 0.9811 - val_loss: 0.1270 - val_accuracy: 0.9804\n",
            "Epoch 70/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1244 - accuracy: 0.9806 - val_loss: 0.1261 - val_accuracy: 0.9807\n",
            "Epoch 71/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1232 - accuracy: 0.9817 - val_loss: 0.1248 - val_accuracy: 0.9825\n",
            "Epoch 72/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1221 - accuracy: 0.9815 - val_loss: 0.1237 - val_accuracy: 0.9804\n",
            "Epoch 73/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1212 - accuracy: 0.9817 - val_loss: 0.1232 - val_accuracy: 0.9804\n",
            "Epoch 74/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1203 - accuracy: 0.9817 - val_loss: 0.1222 - val_accuracy: 0.9804\n",
            "Epoch 75/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1194 - accuracy: 0.9818 - val_loss: 0.1210 - val_accuracy: 0.9800\n",
            "Epoch 76/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1185 - accuracy: 0.9816 - val_loss: 0.1201 - val_accuracy: 0.9818\n",
            "Epoch 77/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1176 - accuracy: 0.9822 - val_loss: 0.1193 - val_accuracy: 0.9807\n",
            "Epoch 78/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1167 - accuracy: 0.9810 - val_loss: 0.1187 - val_accuracy: 0.9804\n",
            "Epoch 79/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1159 - accuracy: 0.9824 - val_loss: 0.1179 - val_accuracy: 0.9807\n",
            "Epoch 80/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1151 - accuracy: 0.9810 - val_loss: 0.1171 - val_accuracy: 0.9836\n",
            "Epoch 81/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1143 - accuracy: 0.9826 - val_loss: 0.1160 - val_accuracy: 0.9821\n",
            "Epoch 82/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1135 - accuracy: 0.9817 - val_loss: 0.1161 - val_accuracy: 0.9804\n",
            "Epoch 83/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1129 - accuracy: 0.9810 - val_loss: 0.1145 - val_accuracy: 0.9818\n",
            "Epoch 84/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1121 - accuracy: 0.9817 - val_loss: 0.1138 - val_accuracy: 0.9829\n",
            "Epoch 85/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1114 - accuracy: 0.9816 - val_loss: 0.1130 - val_accuracy: 0.9825\n",
            "Epoch 86/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1107 - accuracy: 0.9821 - val_loss: 0.1127 - val_accuracy: 0.9804\n",
            "Epoch 87/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1100 - accuracy: 0.9815 - val_loss: 0.1122 - val_accuracy: 0.9804\n",
            "Epoch 88/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1094 - accuracy: 0.9827 - val_loss: 0.1111 - val_accuracy: 0.9829\n",
            "Epoch 89/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1086 - accuracy: 0.9815 - val_loss: 0.1104 - val_accuracy: 0.9818\n",
            "Epoch 90/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1080 - accuracy: 0.9818 - val_loss: 0.1100 - val_accuracy: 0.9818\n",
            "Epoch 91/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1073 - accuracy: 0.9827 - val_loss: 0.1100 - val_accuracy: 0.9804\n",
            "Epoch 92/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1066 - accuracy: 0.9817 - val_loss: 0.1094 - val_accuracy: 0.9800\n",
            "Epoch 93/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1061 - accuracy: 0.9822 - val_loss: 0.1078 - val_accuracy: 0.9829\n",
            "Epoch 94/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1055 - accuracy: 0.9815 - val_loss: 0.1078 - val_accuracy: 0.9804\n",
            "Epoch 95/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1049 - accuracy: 0.9814 - val_loss: 0.1067 - val_accuracy: 0.9818\n",
            "Epoch 96/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1043 - accuracy: 0.9821 - val_loss: 0.1065 - val_accuracy: 0.9807\n",
            "Epoch 97/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1039 - accuracy: 0.9828 - val_loss: 0.1058 - val_accuracy: 0.9789\n",
            "Epoch 98/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1034 - accuracy: 0.9814 - val_loss: 0.1052 - val_accuracy: 0.9818\n",
            "Epoch 99/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1026 - accuracy: 0.9817 - val_loss: 0.1045 - val_accuracy: 0.9825\n",
            "Epoch 100/100\n",
            "112/112 [==============================] - 0s 1ms/step - loss: 0.1021 - accuracy: 0.9819 - val_loss: 0.1041 - val_accuracy: 0.9825\n"
          ]
        }
      ],
      "source": [
        "# multinomial classification 예제\n",
        "# bmi 데이터를 가지고 다중 분류에 대한 학습, 예측 정확도 측정해보기\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# 정규화 키랑 몸무게 차이가 큼\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# raw data loading 파일 가지고 오기\n",
        "\n",
        "df = pd.read_csv('./data/bmi/bmi.csv',skiprows=3)\n",
        "#위에 3줄부터 사용 못하는 부분  #3행부터 읽어라\n",
        "display(df.head(), df.shape) # (20000, 3)\n",
        "\n",
        "# 데이터 전처리부터 해야함\n",
        "# 1. 결측치 부터 확인\n",
        "print(df.isnull().sum()) # 컬럼 결치값 합치기  상태보니 결치값 없음 있으면 drop\n",
        "\n",
        "# 2. 이상치도 없다.box plot 같은 걸로 확인해보기\n",
        "#boxplot 그림 ~\n",
        "\n",
        "# 3. 데이터의 편향 같은게 있는지\n",
        "\n",
        "#데이터 전처리 확인 하기\n",
        "\n",
        "# 데이터를 나누어서 처리하기\n",
        "\n",
        "# split # data 4개로 쪼개버림\n",
        "x_data_train, x_data_test, t_data_train, t_data_test =  \\\n",
        "train_test_split(df[[\"height\",\"weight\"]].values,  # 2차원 파일 values\n",
        "                df['label'].values.reshape(-1,1), #2차원 reshape (-1,1) 1행열\n",
        "                test_size=0.3, # 30% 6000 test 평가 70% 14000는 학습 활용\n",
        "                random_state=0  # 다음 실행 seed 값 랜덤 그대로 저장 변경x\n",
        "                ) # one-hot ecoding 써야함 kears 가 알아서 작업처리함\n",
        "\n",
        "# 정규화 진행 , 분류값이여서 정규화 할 필요없다  x_data 에서만 하면 된다.\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(x_data_train) # 최대,최소 알려줌\n",
        "\n",
        "x_data_train_norm = scaler.transform(x_data_train)\n",
        "x_data_test_norm = scaler.transform(x_data_test)\n",
        "\n",
        "# 변수 필요 만들기 # test 정규화\n",
        "\n",
        "# keras model\n",
        "keras_model = Sequential()\n",
        "\n",
        "# model안의 layer 추가 add\n",
        "keras_model.add(Flatten(input_shape=(2, ))) # input layer 부터 현재 독립변수 2개\n",
        "keras_model.add(Dense(3, activation='softmax' )) # class 3개여서\n",
        "\n",
        "# model 설정   # 2진 binary_cross #categorical 다양한 클래스 #sparse 너가 알아서해\n",
        "# 평가를 기준 잡자.metrics=['accuracy'] 평가기준 기본적으로\n",
        "# 1e-4 에서 1e-2 변경\n",
        "keras_model.compile(optimizer=Adam(learning_rate=1e-2),\n",
        "                   loss='sparse_categorical_crossentropy',\n",
        "                   metrics=['accuracy']\n",
        "                   )\n",
        "\n",
        "# 학습시작 #fit 반복으로\n",
        "# 정규화 데이터 넣어야 norm\n",
        "# t_data_train 학습\n",
        "# 14000 데이터 가지고 100번 학습\n",
        "# 몇번 반복 한방 데이터 크면 못하니 데이터 배치해서 10개씩 짤라서\n",
        "# batch_size 100개 씩 해서 데이터 넣어서 학습 시켜라\n",
        "# verbose 한줄씩 출력\n",
        "# 14000개 데이터를 0.2로 짤라서 2800개에 validation 으로\n",
        "\n",
        "result = keras_model.fit(x_data_train_norm,\n",
        "               t_data_train,\n",
        "                epochs=100,\n",
        "                batch_size=100,\n",
        "                verbose=1,\n",
        "                validation_split=0.2\n",
        "               )\n",
        "# result 변수 받음 # validation 나누어서 처리\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8930f94",
      "metadata": {
        "id": "a8930f94",
        "outputId": "1bfe09bc-50df-4b5d-8547-93f48dce655a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "188/188 [==============================] - 0s 614us/step - loss: 0.0998 - accuracy: 0.9842\n",
            "[0.09983178973197937, 0.98416668176651]\n"
          ]
        }
      ],
      "source": [
        "# 모델 학습이 끝났으니 평가를 진행\n",
        "# test_data 줘야함\n",
        "print(keras_model.evaluate(x_data_test_norm,t_data_test))\n",
        "# 0.98416668176651 98%\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05b42589",
      "metadata": {
        "id": "05b42589",
        "outputId": "33852a5d-5d5a-445c-cd8c-89e8f0c997df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 37ms/step\n",
            "[[6.2908774e-04 9.6497983e-01 3.4391128e-02]]\n"
          ]
        }
      ],
      "source": [
        "# 예측을 해보자. (predict)\n",
        "my_data = np.array([[178,72]]) # 정규화 해서 데이터 넣어야한다.\n",
        "                               #\n",
        "# predict_result = keras_model.predict(my_data)\n",
        "predict_result = keras_model.predict(scaler.transform(my_data))\n",
        "\n",
        "print(predict_result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67e6cfe4",
      "metadata": {
        "id": "67e6cfe4",
        "outputId": "8321deab-eb2b-4e05-8bd9-3cbd584dc65a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 학습 과정중에 나온 데이터를 이용해서 우리 그래프 그리자.\n",
        "# result\n",
        "# print(result.history)\n",
        "# history - dictionary\n",
        "            # key 값은 : loss, accuracy, val_loss, val_accuracy\n",
        "            # value값은 : epoch에 따른 각 값의 list\n",
        "            #loss는 epoch이 증가할 수록 값이 작아져야 정상\n",
        "            # accuracy는 epoch이 증가할 수록 값이 커져야 정상\n",
        "\n",
        "#그래프\n",
        "import matplotlib.pyplot as plt\n",
        "# 나온 결과값이 loss 정상적으로 값이 떨어진다.\n",
        "# plt.plot(result.history['loss'],color='r')\n",
        "\n",
        "plt.plot(result.history['accuracy'],color='g')\n",
        "plt.plot(result.history['val_accuracy'],color='b')\n",
        "# 정상값이 같이 움직인다. val 위,아래 움직인다.\n",
        "\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e6c535a",
      "metadata": {
        "id": "4e6c535a"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:data_env] *",
      "language": "python",
      "name": "conda-env-data_env-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.17"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}