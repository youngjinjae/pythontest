{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "15CR4zk2wTt-cbsD4coZ49aiJ3vVzmyfB",
      "authorship_tag": "ABX9TyPHBgxrI7L0tgO6RL3ofIrc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/youngjinjae/pythontest/blob/main/0727_DeepLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "VvSDiS_ZKyxL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d7b5a3a-5645-4c97-af44-85425e207272"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "228/236 [===========================>..] - ETA: 0s - loss: 0.3225 - accuracy: 0.8999\n",
            "Epoch 1: val_loss improved from inf to 0.20568, saving model to tmp_checkpoint.ckpt\n",
            "236/236 [==============================] - 4s 8ms/step - loss: 0.3177 - accuracy: 0.9013 - val_loss: 0.2057 - val_accuracy: 0.9384\n",
            "Epoch 2/100\n",
            "228/236 [===========================>..] - ETA: 0s - loss: 0.1532 - accuracy: 0.9540\n",
            "Epoch 2: val_loss improved from 0.20568 to 0.18883, saving model to tmp_checkpoint.ckpt\n",
            "236/236 [==============================] - 2s 6ms/step - loss: 0.1534 - accuracy: 0.9541 - val_loss: 0.1888 - val_accuracy: 0.9468\n",
            "Epoch 3/100\n",
            "225/236 [===========================>..] - ETA: 0s - loss: 0.1089 - accuracy: 0.9657\n",
            "Epoch 3: val_loss improved from 0.18883 to 0.18243, saving model to tmp_checkpoint.ckpt\n",
            "236/236 [==============================] - 2s 6ms/step - loss: 0.1092 - accuracy: 0.9656 - val_loss: 0.1824 - val_accuracy: 0.9500\n",
            "Epoch 4/100\n",
            "223/236 [===========================>..] - ETA: 0s - loss: 0.1062 - accuracy: 0.9684\n",
            "Epoch 4: val_loss improved from 0.18243 to 0.15850, saving model to tmp_checkpoint.ckpt\n",
            "236/236 [==============================] - 2s 7ms/step - loss: 0.1062 - accuracy: 0.9685 - val_loss: 0.1585 - val_accuracy: 0.9582\n",
            "Epoch 5/100\n",
            "226/236 [===========================>..] - ETA: 0s - loss: 0.0804 - accuracy: 0.9742\n",
            "Epoch 5: val_loss did not improve from 0.15850\n",
            "236/236 [==============================] - 1s 4ms/step - loss: 0.0824 - accuracy: 0.9739 - val_loss: 0.1615 - val_accuracy: 0.9599\n",
            "Epoch 6/100\n",
            "231/236 [============================>.] - ETA: 0s - loss: 0.0776 - accuracy: 0.9763\n",
            "Epoch 6: val_loss did not improve from 0.15850\n",
            "236/236 [==============================] - 1s 4ms/step - loss: 0.0780 - accuracy: 0.9762 - val_loss: 0.1952 - val_accuracy: 0.9617\n",
            "Epoch 7/100\n",
            "232/236 [============================>.] - ETA: 0s - loss: 0.0828 - accuracy: 0.9750\n",
            "Epoch 7: val_loss did not improve from 0.15850\n",
            "236/236 [==============================] - 1s 4ms/step - loss: 0.0836 - accuracy: 0.9748 - val_loss: 0.1883 - val_accuracy: 0.9565\n",
            "Epoch 8/100\n",
            "224/236 [===========================>..] - ETA: 0s - loss: 0.0631 - accuracy: 0.9819\n",
            "Epoch 8: val_loss did not improve from 0.15850\n",
            "236/236 [==============================] - 1s 4ms/step - loss: 0.0635 - accuracy: 0.9818 - val_loss: 0.1885 - val_accuracy: 0.9580\n",
            "Epoch 9/100\n",
            "234/236 [============================>.] - ETA: 0s - loss: 0.0566 - accuracy: 0.9835\n",
            "Epoch 9: val_loss did not improve from 0.15850\n",
            "Restoring model weights from the end of the best epoch: 4.\n",
            "236/236 [==============================] - 1s 5ms/step - loss: 0.0564 - accuracy: 0.9836 - val_loss: 0.2078 - val_accuracy: 0.9614\n",
            "Epoch 9: early stopping\n"
          ]
        }
      ],
      "source": [
        "# 필요한 모듈 import\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler # 정규화\n",
        "# 어제는 accuracy만 구했다.\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# tensrflow 구현 밑줄 이여도 된다.\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# raw data loading\n",
        "df = pd.read_csv('/content/drive/MyDrive/kcc 3기 colab home/data/mnist/train.csv')\n",
        "\n",
        "# 독립변수와 종속 변수 분리\n",
        "x_data = df.drop('label',axis=1, inplace=False).values\n",
        "t_data = df['label'].values.reshape(-1,1)\n",
        "\n",
        "# 정규화 진행\n",
        "scaler = MinMaxScaler()\n",
        "# 최대 최소 알아야 사용가능\n",
        "scaler.fit(x_data)\n",
        "x_data_norm = scaler.transform(x_data)\n",
        "\n",
        "# train 과 test 데이터 분리\n",
        "x_data_train_norm, x_data_test_norm, t_data_train, t_data_test = \\\n",
        "train_test_split(x_data_norm,\n",
        "                t_data,\n",
        "                test_size=0.3,\n",
        "                random_state=0)\n",
        "\n",
        "# kears model 생성\n",
        "keras_model = Sequential()\n",
        "\n",
        "# layer 를추가\n",
        "keras_model.add(Flatten(input_shape=(784,)))\n",
        "\n",
        "## hiddenlayer deep #relu로 변경 actvi 수학식\n",
        "keras_model.add(Dense(256, activation='relu'))\n",
        "keras_model.add(Dense(128, activation='relu'))\n",
        "\n",
        "\n",
        "keras_model.add(Dense(10, activation='softmax')) # class 표현 분류의 갯수\n",
        "\n",
        "# softmax는 다중 분류시 그냥 분류시는 아님\n",
        "\n",
        "# model 설정\n",
        "keras_model.compile(optimizer=Adam(learning_rate=1e-2),\n",
        "                    loss='sparse_categorical_crossentropy',\n",
        "                   metrics=['accuracy']\n",
        "                   )# 평가 metrics\n",
        "#### deep\n",
        "# 중간지점 저장 하는거나 함수 적절하게 대체해줌\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "my_callback = ModelCheckpoint(filepath='tmp_checkpoint.ckpt',\n",
        "                              save_weight_only=True,\n",
        "                              save_best_only=True,\n",
        "                              mointor='val_loss',\n",
        "                              verbose=1\n",
        "                              )\n",
        "#조기종료에 대해 deep\n",
        "from tensorflow.keras.callbacks import EarlyStopping # 조기 종료 모듈\n",
        "earlystopping_callback = EarlyStopping(monitor='val_loss',\n",
        "                                       patience=5,\n",
        "                                       verbose=1,\n",
        "                                       restore_best_weights=True\n",
        "                                       )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 파일 위치 저장, 저장, 어느성능에 따라 최고 높은거만 저장 best=flase는 폭에따라\n",
        "# 모니터 val_loss , 1은 한줄씩~ call 잡음\n",
        "\n",
        "\n",
        "# model 학습 call 추가 deep\n",
        "keras_model_result = keras_model.fit(x_data_train_norm,\n",
        "                                    t_data_train,\n",
        "                                    epochs=100,\n",
        "                                     batch_size=100,\n",
        "                                     verbose=1,\n",
        "                                     callbacks=[my_callback,earlystopping_callback],\n",
        "                                     validation_split=0.2\n",
        "                                    ) # 몇개 짜를거야 val 0% 평가\n",
        "#89.3% 정도 # callback 추가 조지종료 early 해봣자 값 똑같다\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 평가\n",
        "print(keras_model.evaluate(x_data_test_norm,t_data_test)) #89.6%\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "print(classification_report(t_data_test,\n",
        " tf.argmax(keras_model.predict(x_data_test_norm),axis=1).numpy()))\n",
        "\n",
        "# 정답 변수, 우리의 예측, 열아니면 행으로 찾아서 predict는 2차원으로\n",
        "# tensorflow 파일 쓰면 안되고 numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HM-mYtviPMsW",
        "outputId": "0eb3167e-81a4-4891-e7ed-42f92f12d31f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "394/394 [==============================] - 1s 4ms/step - loss: 0.8131 - accuracy: 0.9632\n",
            "[0.8131428956985474, 0.96317458152771]\n",
            "394/394 [==============================] - 1s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.97      0.98      1242\n",
            "           1       0.98      0.99      0.98      1429\n",
            "           2       0.96      0.97      0.97      1276\n",
            "           3       0.97      0.95      0.96      1298\n",
            "           4       0.97      0.96      0.97      1236\n",
            "           5       0.98      0.94      0.96      1119\n",
            "           6       0.97      0.98      0.98      1243\n",
            "           7       0.98      0.96      0.97      1334\n",
            "           8       0.86      0.98      0.92      1204\n",
            "           9       0.98      0.92      0.95      1219\n",
            "\n",
            "    accuracy                           0.96     12600\n",
            "   macro avg       0.96      0.96      0.96     12600\n",
            "weighted avg       0.96      0.96      0.96     12600\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 우리 모델 저장\n",
        "\n",
        "keras_model.save('/content/drive/MyDrive/kcc 3기 colab home/my_model.h5')"
      ],
      "metadata": {
        "id": "MMinjjOGv8Ir"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 저장된 우리 모델을 불러보아요.\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "new_model = load_model('/content/drive/MyDrive/kcc 3기 colab home/my_model.h5')\n",
        "\n"
      ],
      "metadata": {
        "id": "anLLWNX8yYNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 만약 modelcheckpoint로 저장된 weight가 존재한다면 어떻게 모델 load 하나요\n",
        "\n",
        "keras_model.load_weights('./tmp_checkpoint.ckpt')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1i6ZM8m4Ev6",
        "outputId": "3cace59b-1d8c-4f2c-c8d4-8457ae17c090"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x78a6700a2d10>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}